# %%
import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_validate
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score


# %% [markdown]
# ## Iniciar e limpar o DataSet

# %% [markdown]
# Dataset

# %%
url = r'C:\projetos\default_of_credit_card_clients__courseware_version_1_21_19.xls'
df_orig = pd.read_excel(url)

df_orig.head()

# %% [markdown]
# Máscara booleana para remover as linhas que contêm valor '0'

# %%
df_zero_mask = (df_orig == 0)

# %% [markdown]
# Identificar todas as colunas a partir da primeira que contêm linhas cujo valor é apenas '0'

# %%
features_zero_mask = df_zero_mask.iloc[:, 1:].all(axis=1)

# %% [markdown]
# Remover linhas zeradas

# %%
df_clean = df_orig.loc[~features_zero_mask, :].copy()

df_clean.head()

# %% [markdown]
# Verificar se há apenas id's únicos

# %%
df_clean['ID'].nunique() == df_clean.shape[0]

# %% [markdown]
# Tranformar os valores das colunas 'EDUCATION' e 'MARRIAGE' que não estão documentados em '4'('outros') e '3'

# %%
df_clean['EDUCATION'].replace(to_replace=[0,5,6], value=4, inplace=True)
df_clean['MARRIAGE'].replace(to_replace=0, value=3, inplace=True)

# %% [markdown]
# Substituir valor 'Not available' da coluna 'PAY_1'

# %%
valid_pay_1_mask = df_clean['PAY_1'] != 'Not available'
df_missing_pay_1 = df_clean.loc[valid_pay_1_mask, :].copy()

df_missing_pay_1.head()

# %%
df_clean.columns

# %%
features_response = df_clean.columns.to_list()
features_response

# %%
items_to_remove = ['ID',
 'SEX',
 'PAY_2',
 'PAY_3',
 'PAY_4',
 'PAY_5',
 'PAY_6',
 'default payment next month']

# %%
features_response = [item for item in features_response if item not in items_to_remove]
features_response

# %%
df_clean['PAY_1']

# %%
df_clean = df_clean[df_clean['PAY_1'] != 'Not available'].copy()
df_clean['PAY_1'] = df_clean['PAY_1'].astype(int)

# %% [markdown]
# ## Imputação de PAY_1 pela moda e dados aleatórios

# %% [markdown]
# Remover os resultados (coluna 'default payment next month') dos dados de treino e teste

# %%
X = df_clean[features_response[:-1]]
y = df_clean['default payment next month']

# %%
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=48, test_size=0.2)

# %%
X_train.iloc[:, 4]

# %% [markdown]
# Mediana e Moda

# %%
np.median(X_train.iloc[:, 4]), X_train.iloc[:, 4].mode()[0]

# %% [markdown]
# Preencher espaços vazios com valores aleatórios de outras linhas da mesma coluna

# %%
np.random.seed(seed=1)
fill_values = [0, np.random.choice(X_train.iloc[:, 4], size=(26664, ), replace=True)]

# %% [markdown]
# Usaremos duas estratégias, primeiro os dados aleatórios e depois a moda, para o preenchimento dos espaços vazios.

# %%
fill_strategy = ['random', 'mode']

# %%
fill_values[-1]

# %% [markdown]
# Verificar que os valores aleatórios seguem a mesma distribuição dos valores preenchidos de PAY_1

# %%
fig, axs = plt.subplots(1, 2)
axs[0].hist(X_train.iloc[:, 4])
axs[1].hist(fill_values[-1])

# %%
k_fold = KFold(n_splits=4, shuffle=True, random_state=1)

# %%
clf = RandomForestClassifier()

# %%
for counter in range(len(fill_values)):
    df_fill_pay_1_filled = df_missing_pay_1.copy()
    df_fill_pay_1_filled['PAY_1'] = fill_values[counter]
    
    X = df_fill_pay_1_filled[features_response[:-1]]
    y = df_fill_pay_1_filled['default payment next month']

    X_fill_pay_1_train, X_fill_pay_1_test, y_fill_pay_1_train, y_fill_pay_1_test = \
    train_test_split(X, y, random_state=24, test_size=0.2)

    X_train_all = np.concatenate((X_train, X_fill_pay_1_train), axis=0)
    y_train_all = np.concatenate((y_train, y_fill_pay_1_train), axis=0)

    imputation_compare_cv = cross_validate(clf, X_train_all, y_train_all, scoring='roc_auc', cv=k_fold,
    n_jobs=-1, verbose=1, return_train_score=True, return_estimator=True)

    test_score = imputation_compare_cv['test_score']
    print (f'{fill_strategy[counter],} imputation\nMédia: {np.mean(test_score)}\nStd: {np.std(test_score)}\n')

# %% [markdown]
# Construir um modelo de classificação multiclasse para imputar os valores faltantes

# %%
pay_1_df = df_clean.copy()
features_for_imputation = pay_1_df.columns.tolist()

items_to_remove = ['ID',
 'SEX',
 'PAY_1'
 'PAY_2',
 'PAY_3',
 'PAY_4',
 'PAY_5',
 'PAY_6',
 'default payment next month']

features_for_imputation = [item for item in features_for_imputation if item not in items_to_remove]
features_for_imputation

# %%
X = pay_1_df[features_for_imputation]
y = pay_1_df['PAY_1']

X_impute_train, X_impute_test, y_impute_train, y_impute_test = \
train_test_split(X, y, random_state=24, test_size=0.2)

# %%
rf_impute_params = {'max_depth': [3, 6, 9, 12], 'n_estimators': [10, 50, 100, 200]}

# %%
cv_rf_impute = GridSearchCV(clf, param_grid=rf_impute_params, scoring='accuracy', cv=4, return_train_score=True)

# %%
cv_rf_impute.fit(X_impute_train, y_impute_train)

# %%
cv_rf_impute.best_score_ 

# %%
y_impute_predict = cv_rf_impute.predict(X_impute_test)

# %%
accuracy_score(y_impute_test, y_impute_predict)

# %%
fig, axs = plt.subplots(1, 2)
axs[0].hist(X_impute_test)
axs[1].hist(y_impute_predict)

# %%
X_impute_all = pay_1_df[features_for_imputation]
y_impute_all = pay_1_df['PAY_1']

# %% [markdown]
# Usar Floresta Aleatória para escolher os melhores parâmetros para substituir os vazios

# %%
rf_impute = RandomForestClassifier(**cv_rf_impute.best_params_)

# %%
rf_impute.fit(X_impute_all, y_impute_all)

# %%
df_fill_pay_1_model = df_missing_pay_1.copy()
df_fill_pay_1_model['PAY_1'].head()

# %%
df_fill_pay_1_model['PAY_1'] = rf_impute.predict(df_fill_pay_1_model[features_for_imputation])
df_fill_pay_1_model['PAY_1'].head()

# %%
X = df_fill_pay_1_filled[features_response[:-1]]
y = df_fill_pay_1_filled['default payment next month']

X_fill_pay_1_train, X_fill_pay_1_test, y_fill_pay_1_train, y_fill_pay_1_test = \
train_test_split(X, y, random_state=24, test_size=0.2)

X_train_all = np.concatenate((X_train, X_fill_pay_1_train), axis=0)
y_train_all = np.concatenate((y_train, y_fill_pay_1_train), axis=0)

imputation_compare_cv = cross_validate(clf, X_train_all, y_train_all, scoring='roc_auc', cv=k_fold,
n_jobs=-1, verbose=1, return_train_score=True, return_estimator=True)

test_score = imputation_compare_cv['test_score']
print (f'{fill_strategy[counter],} imputation\nMédia: {np.mean(test_score)}\nStd: {np.std(test_score)}\n')

# %% [markdown]
# Usaremos a "moda"

# %%
df_fill_pay_1_model['PAY_1'] = np.zeros_like(df_fill_pay_1_model['PAY_1'].values)
df_fill_pay_1_model['PAY_1'].unique()

X_fill_pay_1_train, X_fill_pay_1_test, y_fill_pay_1_train, y_fill_pay_1_test = \
    train_test_split(X, y, random_state=24, test_size=0.2)

X_train_all = np.concatenate((X_train, X_fill_pay_1_train), axis=0)
y_train_all = np.concatenate((y_train, y_fill_pay_1_train), axis=0)

X_test_all = np.concatenate((X_test, X_fill_pay_1_test), axis=0)
y_test_all = np.concatenate((y_test, y_fill_pay_1_test), axis=0)

imputation_compare_cv = cross_validate(clf, X_train_all, y_train_all, scoring='roc_auc', cv=k_fold,
                                     n_jobs=-1, verbose=1, return_train_score=True, return_estimator=True)

test_score = imputation_compare_cv['test_score']
print(f'{fill_strategy [counter]} imputation\nMean: {np.mean(test_score)}\nStd: {np.std(test_score)}\n')

# %%
clf.fit(X_train_all, y_train_all)

# %%
y_test_all_predict_proba = clf.predict_proba(X_test_all)

# %%
roc_auc_score(y_test_all, y_test_all_predict_proba[:, 1])

# %% [markdown]
# ### Caracterizar custos e economias

# %%
thresholds = np.linspace(0, 1, 101)

# %%
df_clean[features_response[:-1]].columns[5]

# %% [markdown]
# Verificar qual o retorno financeiro médio trazodo por cada cliente

# %%
savings_per_default = np.mean(X_test_all[:, 5])
savings_per_default

# %%
## Dados que simulam a situação concreta
cost_per_counseling = 7500

effectiveness = 0.7

# %%
n_pos_pred = np.empty_like(thresholds)
cost_of_all_counselings = np.empty_like(thresholds)
n_true_pos = np.empty_like(thresholds)
savings_all_counselings = np.empty_like(thresholds)
savings_based_on_balances = np.empty_like(thresholds)

# %%
counter = 0
for threshold in thresholds:
    pos_pred = y_test_all_predict_proba[:, 1] > threshold
    n_pos_pred[counter] = sum(pos_pred)
    
    cost_of_all_counselings[counter] = n_pos_pred[counter] * cost_per_counseling
    
    true_pos = pos_pred & y_test_all.astype(bool)
    n_true_pos[counter] = sum(true_pos)
    
    savings_all_counselings[counter] = n_true_pos[counter] * savings_per_default * effectiveness
    counter += 1
    
net_savings = savings_all_counselings - cost_of_all_counselings

plt.plot(thresholds, net_savings)
plt.grid(True)

# %%
max_savings_ix = np.argmax(net_savings)
thresholds[max_savings_ix]

# %% [markdown]
# Retorno financeiro em moeda, conforme o projeto

# %%
net_savings[max_savings_ix]


